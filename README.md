# Text-To-Face
Repository containing the work of the Text To face converter used for Metahuman


# Already Done Projects

1.Jali Lip Sync-https://jaliresearch.com/

How do they work
1. An input speech transcript and corresponding audio soundtrack is taken as input.
2. Forced alignment is employed to align utterances in the
soundtrack to the text, giving an output time series containing a sequence of phonemes [Brugnara et al. 1993].
3. Audio, text and alignment information are combined to give
text/phoneme and phoneme/audio correspondences.
Lip-synchronization viseme action units are computed first by
extracting jaw and lip motions for individual phonemes. Humans, however, do not articulate each phoneme separately.
We thus blend the corresponding visemes into co-articulated
action units that more accurately track real human speech
[Deng et al. 2006; Jurafsky and Martin 2008](https://ieeexplore.ieee.org/document/1703372/citations#citations)
Ref-[https://www.dgp.toronto.edu/~elf/JALISIG16.pdf]
